#!/usr/bin/env python3
"""
Whisperæ–‡å­—èµ·ã“ã—Webã‚¢ãƒ—ãƒªï¼ˆè©³ç´°è¨­å®šç‰ˆï¼‰
"""

import os
import sys
import time
import tempfile
import inspect
from functools import lru_cache
from datetime import datetime

import streamlit as st
import torch
import whisper

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Whisperæ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«ï¼ˆè©³ç´°ç‰ˆï¼‰",
    page_icon="ğŸ›ï¸",
    layout="wide"
)


@st.cache_resource
def load_whisper_model(model_name: str):
    """Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ï¼‰"""
    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = "mps"
    else:
        device = "cpu"
    return whisper.load_model(model_name, device=device)


def check_ffmpeg():
    """FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    if os.system("ffmpeg -version > /dev/null 2>&1") != 0:
        st.error(
            "âš ï¸ FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚https://ffmpeg.org/download.html ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        st.stop()


def get_available_models():
    """åˆ©ç”¨å¯èƒ½ãªWhisperãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’è¿”ã™"""
    return ["tiny", "base", "small", "medium", "large"]


@lru_cache(maxsize=1)
def decoding_option_names():
    """åˆ©ç”¨å¯èƒ½ãªDecodingOptionsã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—"""
    try:
        return set(inspect.signature(whisper.decoding.DecodingOptions.__init__).parameters.keys())
    except (AttributeError, ValueError):
        return set()


@lru_cache(maxsize=1)
def transcribe_option_names():
    """Whisper.transcribe ãŒå—ã‘ä»˜ã‘ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—"""
    try:
        transcribe_fn = whisper.model.Whisper.transcribe  # type: ignore[attr-defined]
        params = set(inspect.signature(transcribe_fn).parameters.keys())
        params.discard("self")
        return params
    except (AttributeError, ValueError):
        return set()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ›ï¸ Whisperæ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«ï¼ˆè©³ç´°è¨­å®šç‰ˆï¼‰")
    st.markdown(
        """
        OpenAI Whisper ã®é«˜åº¦ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´ã—ãªãŒã‚‰ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã€‚
        """
    )

    # FFmpegç¢ºèª
    check_ffmpeg()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    st.sidebar.title("è¨­å®š")

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_option = st.sidebar.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’é¸æŠ",
        options=get_available_models(),
        index=1,
        help="ãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã„ã»ã©ç²¾åº¦ã¯ä¸ŠãŒã‚Šã¾ã™ãŒã€å‡¦ç†æ™‚é–“ã‚‚å¢—ãˆã¾ã™ã€‚"
    )

    # è¨€èªé¸æŠ
    language_option = st.sidebar.selectbox(
        "è¨€èªã‚’é¸æŠï¼ˆè‡ªå‹•æ¤œå‡ºã™ã‚‹å ´åˆã¯ç©ºæ¬„ï¼‰",
        options=["", "en", "ja", "zh", "de", "fr", "es", "ko", "ru"],
        index=0,
        format_func=lambda x: {
            "": "è‡ªå‹•æ¤œå‡º", "en": "è‹±èª", "ja": "æ—¥æœ¬èª", "zh": "ä¸­å›½èª",
            "de": "ãƒ‰ã‚¤ãƒ„èª", "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª", "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
            "ko": "éŸ“å›½èª", "ru": "ãƒ­ã‚·ã‚¢èª"
        }.get(x, x),
        help="éŸ³å£°ã®è¨€èªã‚’æŒ‡å®šã—ã¾ã™ã€‚è‡ªå‹•æ¤œå‡ºã‚‚å¯èƒ½ã§ã™ã€‚"
    )

    # ã‚¿ã‚¹ã‚¯é¸æŠ
    task_option = st.sidebar.radio(
        "ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ",
        options=["transcribe", "translate"],
        format_func=lambda x: "æ–‡å­—èµ·ã“ã—ï¼ˆåŒã˜è¨€èªï¼‰" if x == "transcribe" else "ç¿»è¨³ï¼ˆè‹±èªï¼‰",
        help="translate ã‚’é¸ã¶ã¨è‹±èªã¸ã®ç¿»è¨³çµæœãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚"
    )

    st.sidebar.markdown("---")

    # è©³ç´°è¨­å®š
    with st.sidebar.expander("è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
        temperature = st.slider(
            "temperature",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            step=0.01,
            help="ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ã€‚0.0ã§æ±ºå®šçš„ã€å€¤ã‚’ä¸Šã’ã‚‹ã¨å¤šæ§˜æ€§ãŒå¢—ãˆã¾ã™ã€‚"
        )
        temperature_increment = st.slider(
            "temperature_increment_on_fallback",
            min_value=0.0,
            max_value=0.5,
            value=0.2,
            step=0.05,
            help="ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—æ™‚ã«æ¸©åº¦ã‚’ä¸Šã’ã‚‹é‡ã€‚"
        )
        best_of = st.number_input(
            "best_ofï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°ï¼‰",
            min_value=1,
            max_value=10,
            value=1,
            step=1,
            help="æ¸©åº¦ > 0 ã®ã¨ãæœ‰åŠ¹ã€‚å€™è£œã‚’è¤‡æ•°ç”Ÿæˆã—ã¦ãƒ™ã‚¹ãƒˆã‚’é¸ã³ã¾ã™ã€‚"
        )
        beam_size = st.number_input(
            "beam_sizeï¼ˆãƒ“ãƒ¼ãƒ å¹…ï¼‰",
            min_value=1,
            max_value=10,
            value=5,
            step=1,
            help="ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã®å¹…ã€‚é«˜ã„ã»ã©ç²¾åº¦ã¯ä¸ŠãŒã‚Šã¾ã™ãŒé…ããªã‚Šã¾ã™ã€‚"
        )
        patience = st.slider(
            "patience",
            min_value=0.0,
            max_value=2.0,
            value=1.0,
            step=0.1,
            help="ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ã©ã®ç¨‹åº¦ç¶šã‘ã‚‹ã‹ã€‚1.0ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€‚"
        )
        length_penalty = st.slider(
            "length_penalty",
            min_value=0.1,
            max_value=2.0,
            value=1.0,
            step=0.1,
            help="1.0ã§ç„¡åŠ¹ã€‚é«˜ãã™ã‚‹ã¨é•·ã„å‡ºåŠ›ãŒæŠ‘åˆ¶ã•ã‚Œã¾ã™ã€‚"
        )
        condition_on_previous_text = st.checkbox(
            "condition_on_previous_textï¼ˆæ–‡è„ˆã‚’å¼•ãç¶™ãï¼‰",
            value=True,
            help="é•·æ™‚é–“ãƒ•ã‚¡ã‚¤ãƒ«ã§èª¤èªè­˜ãŒå¤šã„å ´åˆã€ã‚ªãƒ•ã«ã™ã‚‹ã¨æ”¹å–„ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"
        )
        vad_filter = st.checkbox(
            "vad_filterï¼ˆç„¡éŸ³éƒ¨åˆ†ã‚’é™¤å»ï¼‰",
            value=False,
            help="Voice Activity Detection ã‚’ä½¿ã„ã€é•·ã„ç„¡éŸ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
        )
        word_timestamps = st.checkbox(
            "word_timestampsï¼ˆå˜èªã”ã¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰",
            value=False,
            help="ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®å˜èªå˜ä½ã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ã—ã¾ã™ã€‚å‡¦ç†ãŒé…ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
        )
        initial_prompt = st.text_area(
            "initial_prompt / prompt",
            value="",
            help="å›ºæœ‰åè©ã‚„æ–‡ä½“ãªã©ã€ãƒ¢ãƒ‡ãƒ«ã«è¦šãˆã¦ãŠã„ã¦ã»ã—ã„æ–‡è„ˆã‚’å…¥åŠ›ã—ã¾ã™ã€‚"
        )
        compression_ratio_threshold = st.slider(
            "compression_ratio_threshold",
            min_value=1.0,
            max_value=5.0,
            value=2.4,
            step=0.1,
            help="ãƒãƒ•ãƒãƒ³åœ§ç¸®ã§é«˜ã™ãã‚‹å ´åˆã¯å¤±æ•—ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚"
        )
        logprob_threshold = st.slider(
            "logprob_threshold",
            min_value=-5.0,
            max_value=0.0,
            value=-1.0,
            step=0.1,
            help="å¹³å‡å¯¾æ•°ç¢ºç‡ãŒã“ã®å€¤ã‚’ä¸‹å›ã‚‹ã¨å¤±æ•—ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚"
        )
        no_speech_threshold = st.slider(
            "no_speech_threshold",
            min_value=0.0,
            max_value=1.0,
            value=0.6,
            step=0.05,
            help="ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ã€‚é«˜ãã™ã‚‹ã¨ç„¡éŸ³æ‰±ã„ã•ã‚Œã‚„ã™ããªã‚Šã¾ã™ã€‚"
        )
        fp16 = st.checkbox(
            "fp16ï¼ˆåŠç²¾åº¦ï¼‰",
            value=True,
            help="GPU ã§ã®åŠç²¾åº¦è¨ˆç®—ã‚’æœ‰åŠ¹åŒ–ã€‚CPU/MPSã§å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚ªãƒ•ã«ã—ã¾ã™ã€‚"
        )

    # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±è¡¨ç¤º
    if torch.cuda.is_available():
        device_for_display = "GPU (CUDA)"
    elif torch.backends.mps.is_available():
        device_for_display = "Apple Silicon (MPS)"
    else:
        device_for_display = "CPU"
    st.sidebar.info(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device_for_display}")

    if device_for_display == "CPU":
        st.sidebar.warning("GPUãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ãŒé…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    elif device_for_display == "Apple Silicon (MPS)":
        st.sidebar.warning("Apple Silicon ã® MPS ã‚µãƒãƒ¼ãƒˆã¯é™å®šçš„ã§ã™ã€‚å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")

    st.sidebar.markdown("---")
    st.sidebar.markdown("[GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/yourusername/whisper-transcription)")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["mp3", "wav", "m4a", "ogg", "flac"],
        help="å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: MP3, WAV, M4A, OGG, FLAC"
    )

    if uploaded_file is None:
        st.info("ğŸ‘† éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        with st.expander("ä½¿ã„æ–¹"):
            st.markdown(
                """
                1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ãƒ»è¨€èªãƒ»ã‚¿ã‚¹ã‚¯ãƒ»ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®š
                2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                3. ã€Œæ–‡å­—èµ·ã“ã—é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
                4. çµæœã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                """
            )
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
    file_size_mb = uploaded_file.size / (1024 * 1024)
    st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name} ({file_size_mb:.2f} MB)")

    # éŸ³å£°å†ç”Ÿ
    st.audio(uploaded_file, format=f"audio/{uploaded_file.name.split('.')[-1]}")

    # æ–‡å­—èµ·ã“ã—ãƒœã‚¿ãƒ³
    if not st.button("æ–‡å­—èµ·ã“ã—é–‹å§‹", type="primary"):
        return

    # å‡¦ç†é–‹å§‹
    with st.spinner("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­..."):
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            temp_filename = tmp_file.name

        try:
            # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
            load_start = time.time()
            status_placeholder = st.empty()
            status_placeholder.text("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            model = load_whisper_model(model_option)
            load_end = time.time()
            status_placeholder.text(f"ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼ˆ{load_end - load_start:.2f}ç§’ï¼‰")

            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ§‹ç¯‰
            transcribe_options = {
                "temperature": temperature,
                "best_of": best_of,
                "beam_size": beam_size,
                "patience": patience,
                "length_penalty": length_penalty,
                "condition_on_previous_text": condition_on_previous_text,
                "vad_filter": vad_filter,
                "word_timestamps": word_timestamps,
                "compression_ratio_threshold": compression_ratio_threshold,
                "logprob_threshold": logprob_threshold,
                "no_speech_threshold": no_speech_threshold,
                "task": task_option,
                "fp16": fp16,
            }

            if "temperature_increment_on_fallback" in decoding_option_names():
                transcribe_options["temperature_increment_on_fallback"] = temperature_increment
            elif temperature_increment > 0 and temperature < 1.0:
                # æœªå¯¾å¿œç’°å¢ƒã§ã¯æ¸©åº¦ã®å€™è£œã‚’ãƒªã‚¹ãƒˆæŒ‡å®šã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æ¨¡å€£
                steps = int((1.0 - temperature) / temperature_increment) + 1
                temp_candidates = [
                    min(1.0, round(temperature + i * temperature_increment, 4))
                    for i in range(max(1, steps))
                ]
                # é †åºã‚’ä¿ã£ãŸã¾ã¾é‡è¤‡ã‚’é™¤å»
                transcribe_options["temperature"] = tuple(dict.fromkeys(temp_candidates))

            if language_option:
                transcribe_options["language"] = language_option
            if initial_prompt.strip():
                transcribe_options["initial_prompt"] = initial_prompt.strip()

            allowed_transcribe_keys = transcribe_option_names()
            if allowed_transcribe_keys:
                transcribe_options = {
                    key: value for key, value in transcribe_options.items()
                    if key in allowed_transcribe_keys
                }

            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            status_placeholder.text("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­...")
            transcribe_start = time.time()
            result = model.transcribe(temp_filename, **transcribe_options)
            transcribe_end = time.time()
            status_placeholder.empty()

            # æ™‚é–“è¨ˆç®—
            transcribe_time = transcribe_end - transcribe_start
            total_time = transcribe_end - load_start

            # çµæœè¡¨ç¤º
            st.markdown("### æ–‡å­—èµ·ã“ã—çµæœ")
            st.success(f"å‡¦ç†å®Œäº†ï¼ˆæ–‡å­—èµ·ã“ã—: {transcribe_time:.2f}ç§’ã€åˆè¨ˆ: {total_time:.2f}ç§’ï¼‰")

            st.markdown("#### ãƒ†ã‚­ã‚¹ãƒˆ")
            st.text_area(
                label="",
                value=result.get("text", ""),
                height=200
            )

            st.download_button(
                label="ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result.get("text", ""),
                file_name=f"{os.path.splitext(uploaded_file.name)[0]}_transcript.txt",
                mime="text/plain"
            )

            with st.expander("è©³ç´°ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰"):
                table_data = []
                timestamp_text = ""

                for segment in result.get("segments", []):
                    start_time = segment.get("start", 0.0)
                    end_time = segment.get("end", 0.0)
                    text = segment.get("text", "")

                    start_formatted = datetime.utcfromtimestamp(start_time).strftime("%H:%M:%S.%f")[:-3]
                    end_formatted = datetime.utcfromtimestamp(end_time).strftime("%H:%M:%S.%f")[:-3]

                    table_data.append({
                        "é–‹å§‹": start_formatted,
                        "çµ‚äº†": end_formatted,
                        "ãƒ†ã‚­ã‚¹ãƒˆ": text
                    })

                    timestamp_text += f"[{start_formatted} --> {end_formatted}] {text}\n"

                    if word_timestamps and segment.get("words"):
                        timestamp_text += "".join(
                            f"    ({datetime.utcfromtimestamp(word['start']).strftime('%H:%M:%S.%f')[:-3]}"
                            f" - {datetime.utcfromtimestamp(word['end']).strftime('%H:%M:%S.%f')[:-3]}) {word['word']}\n"
                            for word in segment["words"]
                        )

                if table_data:
                    st.table(table_data)
                else:
                    st.info("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

                st.download_button(
                    label="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=timestamp_text,
                    file_name=f"{os.path.splitext(uploaded_file.name)[0]}_transcript_timestamps.txt",
                    mime="text/plain"
                )

            if word_timestamps:
                with st.expander("å˜èªã”ã¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—"):
                    if any(segment.get("words") for segment in result.get("segments", [])):
                        word_lines = []
                        for segment in result.get("segments", []):
                            for word in segment.get("words", []):
                                start_fmt = datetime.utcfromtimestamp(word["start"]).strftime("%H:%M:%S.%f")[:-3]
                                end_fmt = datetime.utcfromtimestamp(word["end"]).strftime("%H:%M:%S.%f")[:-3]
                                word_lines.append(f"{start_fmt} - {end_fmt}: {word['word']}")
                        st.text_area("å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—", "\n".join(word_lines), height=200)
                    else:
                        st.info("å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as exc:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {exc}")
        finally:
            if "temp_filename" in locals() and os.path.exists(temp_filename):
                os.unlink(temp_filename)


if __name__ == "__main__":
    main()
